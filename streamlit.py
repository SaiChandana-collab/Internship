# -*- coding: utf-8 -*-
"""Streamlit.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zJonPG1q2mOLFnbdzp9PimhBLhn-FqWx
"""
import os

aws_access_key_id = os.getenv('AWS_ACCESS_KEY_ID')
aws_secret_access_key = os.getenv('AWS_SECRET_ACCESS_KEY')
aws_region = os.getenv('AWS_DEFAULT_REGION')


"""import streamlit as st
from PIL import Image
import pytesseract
import numpy as np
from sklearn.decomposition import PCA
import cv2
import boto3
import io




def extract_text(image_bytes):
    # Create a Textract client
    client = boto3.client('textract', 
                           aws_access_key_id=aws_access_key_id,
                           aws_secret_access_key=aws_secret_access_key,
                           region_name=aws_region)
    
    # Call Textract
    response = client.detect_document_text(Document={'Bytes': image_bytes})
    
    # Extract text from the response
    text = ''
    for item in response['Blocks']:
        if item['BlockType'] == 'LINE':
            text += item['Text'] + '\n'
    
    return text
    
def denoise_approach_3(image):

    # Apply Bilateral Filtering
    image = cv2.fastNlMeansDenoising(image, None, h=10, templateWindowSize=7, searchWindowSize=41)
    denoised_image = cv2.bilateralFilter(image, d=15, sigmaColor=75, sigmaSpace=75)
    denoised_image = cv2.adaptiveThreshold(denoised_image.astype(np.uint8), 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 19)
    return denoised_image

def pca_denoising(image, variance_retained=0.95):
    # Convert image to float32 for PCA
    image_float32 = np.float32(image)

    # Flatten the image into a 1D array
    X = image_float32.flatten()

    # Perform PCA on the flattened image
    pca = PCA(n_components=variance_retained)
    pca.fit(X.reshape(-1, 1))

    # Project the noisy image onto the principal components
    projected_image = pca.transform(X.reshape(-1, 1))

    # Reconstruct the image using the reduced number of principal components
    reconstructed_image = pca.inverse_transform(projected_image).reshape(image.shape)

    # Convert reconstructed image back to uint8
    denoised_image = np.uint8(np.clip(reconstructed_image, 0, 255))

    return denoised_image

def denoise_approach_2(image):

    blurred_image = cv2.GaussianBlur(image, (1, 1), 0)

    # Step 2: Apply PCA Denoising
    blurred_image = cv2.fastNlMeansDenoising(blurred_image, None, 10, 17, 60)
    variance_retained = 0.15
    pca_denoised_image = pca_denoising(blurred_image, variance_retained)

    #_, final_denoised_image = cv2.threshold(pca_denoised_image, 127, 255, cv2.THRESH_BINARY)
    final_denoised_image = cv2.adaptiveThreshold(pca_denoised_image.astype(np.uint8), 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 17)
    return final_denoised_image

# Function to denoise image using Approach 1
def denoise_approach_1(image):
    scale_factor = 2
    org_image = cv2.resize(image, (0, 0), fx=scale_factor, fy=scale_factor)

    # Apply Non-Local Means Denoising
    if len(org_image.shape) == 3 and org_image.shape[2] == 3:
      org_image = cv2.cvtColor(org_image, cv2.COLOR_RGB2GRAY)  # Convert to grayscale if not already
    image = cv2.fastNlMeansDenoising(org_image, None, h=10, templateWindowSize=15, searchWindowSize=71)

    # Apply anisotropic diffusion
    denoised_image = anisotropic_diffusion(image, iterations=30, kappa=20, gamma=0.2, option=1)

    # Apply adaptive thresholding
    denoised_image = cv2.adaptiveThreshold(denoised_image.astype(np.uint8), 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 29)

    return denoised_image

def anisotropic_diffusion(image, iterations, kappa, gamma, option):
    image = image.astype('float32')

    if option == 1:
        image = cv2.GaussianBlur(image, (1, 1), 0)
    elif option == 2:
        image = cv2.medianBlur(image.astype(np.uint8), 3)

    # Pad the image to handle border cases
    image_padded = np.pad(image, ((1, 1), (1, 1)), mode='constant')

    for i in range(iterations):
        # Compute gradients
        nablaN = image_padded[:-2, 1:-1] - image_padded[1:-1, 1:-1]
        nablaS = image_padded[2:, 1:-1] - image_padded[1:-1, 1:-1]
        nablaW = image_padded[1:-1, :-2] - image_padded[1:-1, 1:-1]
        nablaE = image_padded[1:-1, 2:] - image_padded[1:-1, 1:-1]

        # Conductance
        cN = np.exp(-(nablaN / kappa) ** 2)
        cS = np.exp(-(nablaS / kappa) ** 2)
        cW = np.exp(-(nablaW / kappa) ** 2)
        cE = np.exp(-(nablaE / kappa) ** 2)

        # Update image
        image_update = image_padded[1:-1, 1:-1] + gamma * (
            cN * nablaN + cS * nablaS + cW * nablaW + cE * nablaE
        )

        # Update padded image
        image_padded[1:-1, 1:-1] = image_update

    return image_padded[1:-1, 1:-1]


def extract_text_from_image(image):
    return pytesseract.image_to_string(image, lang='eng',config=r'--oem 3 --psm 6')

# Main function to run the Streamlit app
def main():
    st.title("Image Denoising App")
    st.write("Upload your noisy image and choose the best denoising approach.")

    # Upload image
    uploaded_image = st.file_uploader("Upload", type=["jpg", "png", "jpeg", "tif"], accept_multiple_files=False)

    if uploaded_image is not None:
        # Display uploaded image
        image = Image.open(uploaded_image)
        original_height = 200
        denoised_height = 400
        image_np = np.array(image)

        # Calculate the aspect ratio
        aspect_ratio = image_np.shape[1] / image_np.shape[0]

        # Calculate the widths for the new heights
        original_width = int(original_height * aspect_ratio)
        denoised_width = int(denoised_height * aspect_ratio)
        st.image(image, caption='Uploaded Image', use_column_width=True,width=original_width)

        # Apply denoising approaches
        denoised_image_1 = denoise_approach_1(image_np)
        denoised_image_2 = denoise_approach_2(image_np)
        denoised_image_3 = denoise_approach_3(image_np)

        col1, col2, col3 = st.columns([5,5,5])
        with col1:
            st.image(denoised_image_1, caption='Anisotropic Diffusion', use_column_width=True, clamp=True, channels="GRAY", width=denoised_width)
            if st.button('Anisotropic OCR'):
                denoised_image=Image.fromarray(denoised_image_1)
                with io.BytesIO() as buffer:
                   denoised_image.save(buffer, format='PNG')  # Save as PNG or JPG
                   image_bytes = buffer.getvalue()
# Extract text from image
                extracted_text = extract_text(image_bytes)
                st.subheader("Extracted Text:")
                st.write(extracted_text)

        with col2:
            st.image(denoised_image_2, caption='PCA ', use_column_width=True, clamp=True, channels="GRAY", width=denoised_width)
            if st.button('PCA OCR'):
                denoised_image=Image.fromarray(denoised_image_2)
                with io.BytesIO() as buffer:
                   denoised_image.save(buffer, format='PNG')  # Save as PNG or JPG
                   image_bytes = buffer.getvalue()
# Extract text from image
                extracted_text = extract_text(image_bytes)
                st.subheader("Extracted Text:")
                st.write(extracted_text)
                

        with col3:
            st.image(denoised_image_3, caption='Bilateral Filtering', use_column_width=True, clamp=True, channels="GRAY", width=denoised_width)
            if st.button('Bilateral Filtering OCR'):
                denoised_image=Image.fromarray(denoised_image_3)
                with io.BytesIO() as buffer:
                   denoised_image.save(buffer, format='PNG')  # Save as PNG or JPG
                   image_bytes = buffer.getvalue()
# Extract text from image
                extracted_text = extract_text(image_bytes)
                st.subheader("Extracted Text:")
                st.write(extracted_text)
# Run the app
if __name__ == '__main__':
    main()"""





#navbar
import streamlit as st
from PIL import Image
import pytesseract
import numpy as np
from sklearn.decomposition import PCA
import cv2
import boto3
import io




def denoise_approach_5(image):
    def load_image(image):
        img = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
        return img

    def detect_text(image):
        orig = image.copy()
        (H, W) = image.shape[:2]

        (newH, newW) = (H, W)
        if newH % 32 != 0:
            newH = (newH // 32 + 1) * 32
        if newW % 32 != 0:
            newW = (newW // 32 + 1) * 32
        resized_image = cv2.resize(image, (newW, newH))

        net = cv2.dnn.readNet(model_path)

        blob = cv2.dnn.blobFromImage(resized_image, 1.0, (newW, newH), (123.68, 116.78, 103.94), swapRB=True, crop=False)
        net.setInput(blob)

        layer_names = ["feature_fusion/Conv_7/Sigmoid", "feature_fusion/concat_3"]
        (scores, geometry) = net.forward(layer_names)

        (rects, confidences) = decode_predictions(scores, geometry)
        boxes = non_max_suppression(np.array(rects), probs=confidences)

        text_regions = [(x, y, x + w, y + h) for (x, y, w, h) in boxes]
        return text_regions

    def decode_predictions(scores, geometry):
        (num_rows, num_cols) = scores.shape[2:4]
        rects = []
        confidences = []

        for y in range(0, num_rows):
            scores_data = scores[0, 0, y]
            x_data_0 = geometry[0, 0, y]
            x_data_1 = geometry[0, 1, y]
            x_data_2 = geometry[0, 2, y]
            x_data_3 = geometry[0, 3, y]
            angles_data = geometry[0, 4, y]

            for x in range(0, num_cols):
                if scores_data[x] < 0.5:
                    continue

                (offset_x, offset_y) = (x * 4.0, y * 4.0)
                angle = angles_data[x]
                cos = np.cos(angle)
                sin = np.sin(angle)
                h = x_data_0[x] + x_data_2[x]
                w = x_data_1[x] + x_data_3[x]
                end_x = int(offset_x + (cos * x_data_1[x]) + (sin * x_data_2[x]))
                end_y = int(offset_y - (sin * x_data_1[x]) + (cos * x_data_2[x]))
                start_x = int(end_x - w)
                start_y = int(end_y - h)

                rects.append((start_x, start_y, w, h))
                confidences.append(scores_data[x])

        return (rects, confidences)
    def non_max_suppression(boxes, probs=None, overlapThresh=0.3):
        if len(boxes) == 0:
            return []

        if boxes.dtype.kind == "i":
            boxes = boxes.astype("float")

        pick = []
        x1 = boxes[:, 0]
        y1 = boxes[:, 1]
        x2 = boxes[:, 2]
        y2 = boxes[:, 3]

        area = (x2 - x1 + 1) * (y2 - y1 + 1)
        idxs = y2

        if probs is not None:
            idxs = probs

        idxs = np.argsort(idxs)

        while len(idxs) > 0:
            last = len(idxs) - 1
            i = idxs[last]
            pick.append(i)

            xx1 = np.maximum(x1[i], x1[idxs[:last]])
            yy1 = np.maximum(y1[i], y1[idxs[:last]])
            xx2 = np.minimum(x2[i], x2[idxs[:last]])
            yy2 = np.minimum(y2[i], y2[idxs[:last]])

            w = np.maximum(0, xx2 - xx1 + 1)
            h = np.maximum(0, yy2 - yy1 + 1)

            overlap = (w * h) / area[idxs[:last]]

            idxs = np.delete(idxs, np.concatenate(([last], np.where(overlap > overlapThresh)[0])))

        return boxes[pick].astype("int")
    def denoise_ROIs(image, regions):
        denoised_image = image.copy()
        for region in regions:
            x1, y1, x2, y2 = region
            if x1 < 0:
                x1 = 0
            if y1 < 0:
                y1 = 0
            if x2 > image.shape[1]:
                x2 = image.shape[1]
            if y2 > image.shape[0]:
                y2 = image.shape[0]
            roi = denoised_image[y1:y2, x1:x2]
            if roi.size != 0:
                denoised_roi = cv2.fastNlMeansDenoisingColored(roi, None, 10, 10, 7, 21)
                denoised_image[y1:y2, x1:x2] = denoised_roi
        return denoised_image

    image = load_image(image)
    text_regions = detect_text(image)
    denoised_ROIs_image = denoise_ROIs(image, text_regions)
    return denoised_ROIs_image
   


def denoise_approach_6(image):
    sigma_est = np.mean(estimate_sigma(image, multichannel=False))
    patch_kw = dict(patch_size=3,      # 5x5 patches
                    patch_distance=5,  # 13x13 search area
                    multichannel=False)
    denoised = denoise_nl_means(image, h=1.15 * sigma_est, fast_mode=True, **patch_kw)
    return img_as_ubyte(denoised)

def denoise_approach_4(image):

  def kfill(image, k):
        h, w = image.shape
        output_image = image.copy()

        neighborhood_size = k * k
        half_k = k // 2

        # Pad the image to handle edges
        padded_image = np.pad(image, pad_width=half_k, mode='constant', constant_values=255)

        for i in range(half_k, h + half_k):
            for j in range(half_k, w + half_k):
                neighborhood = padded_image[i-half_k:i+half_k+1, j-half_k:j+half_k+1]
                core = neighborhood[1:1+k-2, 1:1+k-2]

                n = np.sum(neighborhood < 127)
                c = 1 if np.any(core < 127) else 0

                if np.all(core >= 127) and n > 3*k-4 and c == 1:
                    output_image[i-half_k, j-half_k] = 0
                elif np.all(core < 127) and n > 3*k-4 and c == 1:
                    output_image[i-half_k, j-half_k] = 255

        return output_image

  k = 11  # Window size for kFill algorithm
  kfill_result = kfill(image, k)
  return kfill_result
    
def apply_non_local_means(image, h, hForColorComponents, templateWindowSize, searchWindowSize):
    return cv2.fastNlMeansDenoisingColored(image, None, h, hForColorComponents, templateWindowSize, searchWindowSize)

def apply_median_blur(image, ksize):
    return cv2.medianBlur(image, ksize)

def apply_histogram_equalization(image, clipLimit, tileGridSize):
    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    lab_planes = list(cv2.split(lab))
    clahe = cv2.createCLAHE(clipLimit=clipLimit, tileGridSize=tileGridSize)
    lab_planes[0] = clahe.apply(lab_planes[0])
    lab = cv2.merge(lab_planes)
    return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)

def apply_bilateral_filter(image, d, sigmaColor, sigmaSpace):
    return cv2.bilateralFilter(image, d, sigmaColor, sigmaSpace)

def apply_fuzzy_logic(image, clipLimit, tileGridSize):
    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    lab_planes = list(cv2.split(lab))
    clahe = cv2.createCLAHE(clipLimit=clipLimit, tileGridSize=tileGridSize)
    lab_planes[0] = clahe.apply(lab_planes[0])
    lab = cv2.merge(lab_planes)
    return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)


# Define denoising functions
def denoise_approach_3(image):
    image = cv2.fastNlMeansDenoising(image, None, h=10, templateWindowSize=7, searchWindowSize=41)
    denoised_image = cv2.bilateralFilter(image, d=15, sigmaColor=75, sigmaSpace=75)
    denoised_image = cv2.adaptiveThreshold(denoised_image.astype(np.uint8), 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 19)
    return denoised_image


def pca_denoising(image, variance_retained=0.95):
    image_float32 = np.float32(image)
    X = image_float32.flatten()
    pca = PCA(n_components=variance_retained)
    pca.fit(X.reshape(-1, 1))
    projected_image = pca.transform(X.reshape(-1, 1))
    reconstructed_image = pca.inverse_transform(projected_image).reshape(image.shape)
    denoised_image = np.uint8(np.clip(reconstructed_image, 0, 255))
    return denoised_image


def denoise_approach_2(image):
    blurred_image = cv2.GaussianBlur(image, (1, 1), 0)
    blurred_image = cv2.fastNlMeansDenoising(blurred_image, None, 10, 17, 60)
    variance_retained = 0.15
    pca_denoised_image = pca_denoising(blurred_image, variance_retained)
    final_denoised_image = cv2.adaptiveThreshold(pca_denoised_image.astype(np.uint8), 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 17)
    return final_denoised_image


def denoise_approach_1(image):
    scale_factor = 2
    org_image = cv2.resize(image, (0, 0), fx=scale_factor, fy=scale_factor)
    if len(org_image.shape) == 3 and org_image.shape[2] == 3:
        org_image = cv2.cvtColor(org_image, cv2.COLOR_RGB2GRAY)
    image = cv2.fastNlMeansDenoising(org_image, None, h=10, templateWindowSize=15, searchWindowSize=71)
    denoised_image = anisotropic_diffusion(image, iterations=30, kappa=2, gamma=0.2, option=1)
    denoised_image = cv2.adaptiveThreshold(denoised_image.astype(np.uint8), 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 29)
    return denoised_image


def anisotropic_diffusion(image, iterations, kappa, gamma, option):
    image = image.astype('float32')
    if option == 1:
        image = cv2.GaussianBlur(image, (1, 1), 0)
    elif option == 2:
        image = cv2.medianBlur(image.astype(np.uint8), 3)
    image_padded = np.pad(image, ((1, 1), (1, 1)), mode='constant')

    for i in range(iterations):
        nablaN = image_padded[:-2, 1:-1] - image_padded[1:-1, 1:-1]
        nablaS = image_padded[2:, 1:-1] - image_padded[1:-1, 1:-1]
        nablaW = image_padded[1:-1, :-2] - image_padded[1:-1, 1:-1]
        nablaE = image_padded[1:-1, 2:] - image_padded[1:-1, 1:-1]

        cN = np.exp(-(nablaN / kappa) ** 2)
        cS = np.exp(-(nablaS / kappa) ** 2)
        cW = np.exp(-(nablaW / kappa) ** 2)
        cE = np.exp(-(nablaE / kappa) ** 2)

        image_update = image_padded[1:-1, 1:-1] + gamma * (
            cN * nablaN + cS * nablaS + cW * nablaW + cE * nablaE
        )
        image_padded[1:-1, 1:-1] = image_update

    return image_padded[1:-1, 1:-1]


def extract_text(image_bytes):
    # Create a Textract client
    client = boto3.client('textract', 
                           aws_access_key_id=aws_access_key_id,
                           aws_secret_access_key=aws_secret_access_key,
                           region_name=aws_region)
    
    # Call Textract
    response = client.detect_document_text(Document={'Bytes': image_bytes})
    
    # Extract text from the response
    text = ''
    for item in response['Blocks']:
        if item['BlockType'] == 'LINE':
            text += item['Text'] + '\n'
    
    return text

    


# Main function to run the Streamlit app
def main():
    st.title("Image Denoising App")
    st.write("Upload your noisy image and explore different denoising methods.")

    # Navbar for selecting denoising method
    navbar = st.sidebar.radio(
        "Navigation",
        ("Anisotropic Diffusion", "PCA Denoising", "Bilateral Filtering","KFill","ETRDA","Non Local Means","Histogram Equalization","Bilateral Filter","Fuzzy Logic")
    )

    # Upload image
    uploaded_image = st.file_uploader("Upload Image", type=["jpg", "png", "jpeg", "tif"])

    if uploaded_image is not None:
        image = Image.open(uploaded_image)
        image_np = np.array(image)
        st.image(image, caption='Uploaded Image', use_column_width=True)
        if st.button(f"Extract Text from original Image"):
            org_image=Image.fromarray(image_np)
            with io.BytesIO() as buffer:
               org_image.save(buffer, format='PNG')  # Save as PNG or JPG
               image_bytes = buffer.getvalue()
            extracted_text = extract_text(image_bytes)
            st.text_area("Extracted Text", extracted_text, height=200)
    if navbar == "Anisotropic Diffusion":
        st.header("Anisotropic Diffusion")
        denoised_image = denoise_approach_1(image_np)
    elif navbar == "PCA Denoising":
        st.header("PCA Denoising")
        denoised_image = denoise_approach_2(image_np)
    elif navbar == "Bilateral Filtering":
        st.header("Bilateral Filtering")
        denoised_image = denoise_approach_3(image_np)
    elif navbar == "KFill":
        st.header("KFill")
        denoised_image = denoise_approach_4(image_np)
    elif navbar == "ETRDA":
        st.header("ETRDA")
        denoised_image = denoise_approach_5(image_np)
    elif navbar == "Non Local Means":
        st.header("Non Local Means")
        denoised_image = denoise_approach_6(image_np)
    elif navbar == "Histogram Equalization":
        st.header("Histogram Equalization")
        denoised_image = denoise_approach_7(image_np)
    elif navbar == "Fuzzy Logic":
        st.header("Fuzzy Logic")
        denoised_image = denoise_approach_9(image_np)
    

        st.image(denoised_image, caption=f"Denoised Image ({navbar})", use_column_width=True, clamp=True, channels="GRAY")

        if st.button(f"Extract Text ({navbar})"):
            denoised_image=Image.fromarray(denoised_image)
            with io.BytesIO() as buffer:
               denoised_image.save(buffer, format='PNG')  # Save as PNG or JPG
               image_bytes = buffer.getvalue()
            extracted_text = extract_text(image_bytes)
            st.text_area("Extracted Text", extracted_text, height=200)


if __name__ == '__main__':
    main()



