# -*- coding: utf-8 -*-
"""Streamlit.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zJonPG1q2mOLFnbdzp9PimhBLhn-FqWx
"""
import os

aws_access_key_id = os.getenv('AWS_ACCESS_KEY_ID')
aws_secret_access_key = os.getenv('AWS_SECRET_ACCESS_KEY')
aws_region = os.getenv('AWS_DEFAULT_REGION')



#navbar
import streamlit as st
from PIL import Image
import pytesseract
import numpy as np
from sklearn.decomposition import PCA
import cv2
import boto3
import io


# karteek methods



def denoise_approach_4(image):

  def kfill(image, k):
        h, w = image.shape
        output_image = image.copy()

        neighborhood_size = k * k
        half_k = k // 2

        # Pad the image to handle edges
        padded_image = np.pad(image, pad_width=half_k, mode='constant', constant_values=255)

        for i in range(half_k, h + half_k):
            for j in range(half_k, w + half_k):
                neighborhood = padded_image[i-half_k:i+half_k+1, j-half_k:j+half_k+1]
                core = neighborhood[1:1+k-2, 1:1+k-2]

                n = np.sum(neighborhood < 127)
                c = 1 if np.any(core < 127) else 0

                if np.all(core >= 127) and n > 3*k-4 and c == 1:
                    output_image[i-half_k, j-half_k] = 0
                elif np.all(core < 127) and n > 3*k-4 and c == 1:
                    output_image[i-half_k, j-half_k] = 255

        return output_image

  k = 11  # Window size for kFill algorithm
  kfill_result = kfill(image, k)
  return kfill_result




#######



# Define denoising functions
def denoise_approach_3(image):
    image = cv2.fastNlMeansDenoising(image, None, h=10, templateWindowSize=7, searchWindowSize=41)
    denoised_image = cv2.bilateralFilter(image, d=15, sigmaColor=75, sigmaSpace=75)
    denoised_image = cv2.adaptiveThreshold(denoised_image.astype(np.uint8), 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 19)
    return denoised_image


def pca_denoising(image, variance_retained=0.95):
    image_float32 = np.float32(image)
    X = image_float32.flatten()
    pca = PCA(n_components=variance_retained)
    pca.fit(X.reshape(-1, 1))
    projected_image = pca.transform(X.reshape(-1, 1))
    reconstructed_image = pca.inverse_transform(projected_image).reshape(image.shape)
    denoised_image = np.uint8(np.clip(reconstructed_image, 0, 255))
    return denoised_image


def denoise_approach_2(image):
    blurred_image = cv2.GaussianBlur(image, (1, 1), 0)
    blurred_image = cv2.fastNlMeansDenoising(blurred_image, None, 10, 17, 60)
    variance_retained = 0.15
    pca_denoised_image = pca_denoising(blurred_image, variance_retained)
    final_denoised_image = cv2.adaptiveThreshold(pca_denoised_image.astype(np.uint8), 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 17)
    return final_denoised_image


def denoise_approach_1(image):
    scale_factor = 2
    org_image = cv2.resize(image, (0, 0), fx=scale_factor, fy=scale_factor)
    if len(org_image.shape) == 3 and org_image.shape[2] == 3:
        org_image = cv2.cvtColor(org_image, cv2.COLOR_RGB2GRAY)
    image = cv2.fastNlMeansDenoising(org_image, None, h=10, templateWindowSize=15, searchWindowSize=71)
    denoised_image = anisotropic_diffusion(image, iterations=30, kappa=5, gamma=0.2, option=1)
    denoised_image = cv2.adaptiveThreshold(denoised_image.astype(np.uint8), 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 29)
    return denoised_image


def anisotropic_diffusion(image, iterations, kappa, gamma, option):
    image = image.astype('float32')
    if option == 1:
        image = cv2.GaussianBlur(image, (1, 1), 0)
    elif option == 2:
        image = cv2.medianBlur(image.astype(np.uint8), 3)
    image_padded = np.pad(image, ((1, 1), (1, 1)), mode='constant')

    for i in range(iterations):
        nablaN = image_padded[:-2, 1:-1] - image_padded[1:-1, 1:-1]
        nablaS = image_padded[2:, 1:-1] - image_padded[1:-1, 1:-1]
        nablaW = image_padded[1:-1, :-2] - image_padded[1:-1, 1:-1]
        nablaE = image_padded[1:-1, 2:] - image_padded[1:-1, 1:-1]

        cN = np.exp(-(nablaN / kappa) ** 2)
        cS = np.exp(-(nablaS / kappa) ** 2)
        cW = np.exp(-(nablaW / kappa) ** 2)
        cE = np.exp(-(nablaE / kappa) ** 2)

        image_update = image_padded[1:-1, 1:-1] + gamma * (
            cN * nablaN + cS * nablaS + cW * nablaW + cE * nablaE
        )
        image_padded[1:-1, 1:-1] = image_update

    return image_padded[1:-1, 1:-1]


def extract_text(image_bytes):
    # Create a Textract client
    client = boto3.client('textract', 
                           aws_access_key_id=aws_access_key_id,
                           aws_secret_access_key=aws_secret_access_key,
                           region_name=aws_region)
    
    # Call Textract
    response = client.detect_document_text(Document={'Bytes': image_bytes})
    
    # Extract text from the response
    text = ''
    for item in response['Blocks']:
        if item['BlockType'] == 'LINE':
            text += item['Text'] + '\n'
    
    return text


# Main function to run the Streamlit app
def main():
    st.title("Image Denoising App")
    st.write("Upload your noisy image and explore different denoising methods.")

    # Navbar for selecting denoising method
    navbar = st.sidebar.radio(
        "Navigation",
        ("Anisotropic Diffusion", "PCA Denoising", "Bilateral Filtering","KFill Denoising")
    )

    # Upload image
    uploaded_image = st.file_uploader("Upload Image", type=["jpg", "png", "jpeg", "tif"])

    if uploaded_image is not None:
        image = Image.open(uploaded_image)
        image_np = np.array(image)
        st.image(image, caption='Uploaded Image', use_column_width=True)
        if st.button(f"Extract Text from Original"):
            org_image=Image.fromarray(image_np)
            with io.BytesIO() as buffer:
               org_image.save(buffer, format='PNG')  # Save as PNG or JPG
               image_bytes = buffer.getvalue()
            extracted_text = extract_text(image_bytes)
            st.text_area("Extracted Text", extracted_text, height=200)

        # Display selected denoising method
        if navbar == "Anisotropic Diffusion":
            st.header("Anisotropic Diffusion")
            denoised_image = denoise_approach_1(image_np)
        elif navbar == "PCA Denoising":
            st.header("PCA Denoising")
            denoised_image = denoise_approach_2(image_np)
        elif navbar == "Bilateral Filtering":
            st.header("Bilateral Filtering")
            denoised_image = denoise_approach_3(image_np)

        st.image(denoised_image, caption=f"Denoised Image ({navbar})", use_column_width=True, clamp=True)

        if st.button(f"Extract Text ({navbar})"):
            denoised_image=Image.fromarray(denoised_image)
            with io.BytesIO() as buffer:
               denoised_image.save(buffer, format='PNG')  # Save as PNG or JPG
               image_bytes = buffer.getvalue()
            extracted_text = extract_text(image_bytes)
            st.text_area("Extracted Text", extracted_text, height=200)


if __name__ == '__main__':
    main()
