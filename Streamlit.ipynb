{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NR0s5np8Swyw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "id": "eGii7yq0S0cX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract\n",
        "!sudo apt install tesseract-ocr\n",
        "!tesseract -v\n",
        "!which tesseract"
      ],
      "metadata": {
        "id": "l0RpRrhdS0Zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "import cv2\n",
        "\n",
        "\n",
        "background_color = \"#F0F2F5\"\n",
        "st.markdown(f\"\"\"\n",
        "<style>\n",
        "    body {{\n",
        "        background-color: {background_color};\n",
        "    }}\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "def denoise_approach_3(image):\n",
        "\n",
        "    # Apply Bilateral Filtering\n",
        "    image = cv2.fastNlMeansDenoising(image, None, h=10, templateWindowSize=7, searchWindowSize=41)\n",
        "    denoised_image = cv2.bilateralFilter(image, d=15, sigmaColor=75, sigmaSpace=75)\n",
        "    denoised_image = cv2.adaptiveThreshold(denoised_image.astype(np.uint8), 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 19)\n",
        "    return denoised_image\n",
        "\n",
        "def pca_denoising(image, variance_retained=0.95):\n",
        "    # Convert image to float32 for PCA\n",
        "    image_float32 = np.float32(image)\n",
        "\n",
        "    # Flatten the image into a 1D array\n",
        "    X = image_float32.flatten()\n",
        "\n",
        "    # Perform PCA on the flattened image\n",
        "    pca = PCA(n_components=variance_retained)\n",
        "    pca.fit(X.reshape(-1, 1))\n",
        "\n",
        "    # Project the noisy image onto the principal components\n",
        "    projected_image = pca.transform(X.reshape(-1, 1))\n",
        "\n",
        "    # Reconstruct the image using the reduced number of principal components\n",
        "    reconstructed_image = pca.inverse_transform(projected_image).reshape(image.shape)\n",
        "\n",
        "    # Convert reconstructed image back to uint8\n",
        "    denoised_image = np.uint8(np.clip(reconstructed_image, 0, 255))\n",
        "\n",
        "    return denoised_image\n",
        "\n",
        "def denoise_approach_2(image):\n",
        "\n",
        "    blurred_image = cv2.GaussianBlur(image, (1, 1), 0)\n",
        "\n",
        "    # Step 2: Apply PCA Denoising\n",
        "    blurred_image = cv2.fastNlMeansDenoising(blurred_image, None, 10, 17, 60)\n",
        "    variance_retained = 0.15\n",
        "    pca_denoised_image = pca_denoising(blurred_image, variance_retained)\n",
        "\n",
        "    #_, final_denoised_image = cv2.threshold(pca_denoised_image, 127, 255, cv2.THRESH_BINARY)\n",
        "    final_denoised_image = cv2.adaptiveThreshold(pca_denoised_image.astype(np.uint8), 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 17)\n",
        "    return final_denoised_image\n",
        "\n",
        "# Function to denoise image using Approach 1\n",
        "def denoise_approach_1(image):\n",
        "    scale_factor = 2\n",
        "    org_image = cv2.resize(image, (0, 0), fx=scale_factor, fy=scale_factor)\n",
        "\n",
        "    # Apply Non-Local Means Denoising\n",
        "    if len(org_image.shape) == 3 and org_image.shape[2] == 3:\n",
        "      org_image = cv2.cvtColor(org_image, cv2.COLOR_RGB2GRAY)  # Convert to grayscale if not already\n",
        "    image = cv2.fastNlMeansDenoising(org_image, None, h=10, templateWindowSize=15, searchWindowSize=71)\n",
        "\n",
        "    # Apply anisotropic diffusion\n",
        "    denoised_image = anisotropic_diffusion(image, iterations=30, kappa=20, gamma=0.2, option=1)\n",
        "\n",
        "    # Apply adaptive thresholding\n",
        "    denoised_image = cv2.adaptiveThreshold(denoised_image.astype(np.uint8), 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 29)\n",
        "\n",
        "    return denoised_image\n",
        "\n",
        "def anisotropic_diffusion(image, iterations, kappa, gamma, option):\n",
        "    image = image.astype('float32')\n",
        "\n",
        "    if option == 1:\n",
        "        image = cv2.GaussianBlur(image, (1, 1), 0)\n",
        "    elif option == 2:\n",
        "        image = cv2.medianBlur(image.astype(np.uint8), 3)\n",
        "\n",
        "    # Pad the image to handle border cases\n",
        "    image_padded = np.pad(image, ((1, 1), (1, 1)), mode='constant')\n",
        "\n",
        "    for i in range(iterations):\n",
        "        # Compute gradients\n",
        "        nablaN = image_padded[:-2, 1:-1] - image_padded[1:-1, 1:-1]\n",
        "        nablaS = image_padded[2:, 1:-1] - image_padded[1:-1, 1:-1]\n",
        "        nablaW = image_padded[1:-1, :-2] - image_padded[1:-1, 1:-1]\n",
        "        nablaE = image_padded[1:-1, 2:] - image_padded[1:-1, 1:-1]\n",
        "\n",
        "        # Conductance\n",
        "        cN = np.exp(-(nablaN / kappa) ** 2)\n",
        "        cS = np.exp(-(nablaS / kappa) ** 2)\n",
        "        cW = np.exp(-(nablaW / kappa) ** 2)\n",
        "        cE = np.exp(-(nablaE / kappa) ** 2)\n",
        "\n",
        "        # Update image\n",
        "        image_update = image_padded[1:-1, 1:-1] + gamma * (\n",
        "            cN * nablaN + cS * nablaS + cW * nablaW + cE * nablaE\n",
        "        )\n",
        "\n",
        "        # Update padded image\n",
        "        image_padded[1:-1, 1:-1] = image_update\n",
        "\n",
        "    return image_padded[1:-1, 1:-1]\n",
        "\n",
        "\n",
        "def extract_text_from_image(image):\n",
        "    return pytesseract.image_to_string(image, lang='eng',config=r'--oem 3 --psm 6')\n",
        "\n",
        "# Main function to run the Streamlit app\n",
        "def main():\n",
        "    st.title(\"Image Denoising App\")\n",
        "    st.write(\"Upload your noisy image and choose the best denoising approach.\")\n",
        "\n",
        "    # Upload image\n",
        "    uploaded_image = st.file_uploader(\"Upload\", type=[\"jpg\", \"png\", \"jpeg\", \"tif\"], accept_multiple_files=False)\n",
        "\n",
        "    if uploaded_image is not None:\n",
        "        # Display uploaded image\n",
        "        image = Image.open(uploaded_image)\n",
        "        original_height = 200\n",
        "        denoised_height = 400\n",
        "        image_np = np.array(image)\n",
        "\n",
        "        # Calculate the aspect ratio\n",
        "        aspect_ratio = image_np.shape[1] / image_np.shape[0]\n",
        "\n",
        "        # Calculate the widths for the new heights\n",
        "        original_width = int(original_height * aspect_ratio)\n",
        "        denoised_width = int(denoised_height * aspect_ratio)\n",
        "        st.image(image, caption='Uploaded Image', use_column_width=True,width=original_width)\n",
        "\n",
        "        # Apply denoising approaches\n",
        "        denoised_image_1 = denoise_approach_1(image_np)\n",
        "        denoised_image_2 = denoise_approach_2(image_np)\n",
        "        denoised_image_3 = denoise_approach_3(image_np)\n",
        "\n",
        "        col1, col2, col3 = st.columns([5,5,5])\n",
        "        with col1:\n",
        "            st.image(denoised_image_1, caption='Anisotropic Diffusion', use_column_width=True, clamp=True, channels=\"GRAY\", width=denoised_width)\n",
        "            if st.button('Anisotropic OCR'):\n",
        "                extracted_text = extract_text_from_image(denoised_image_1)\n",
        "                st.text_area('Extracted Text', extracted_text, height=500)\n",
        "\n",
        "        with col2:\n",
        "            st.image(denoised_image_2, caption='PCA ', use_column_width=True, clamp=True, channels=\"GRAY\", width=denoised_width)\n",
        "            if st.button('PCA OCR'):\n",
        "                extracted_text = extract_text_from_image(denoised_image_2)\n",
        "                st.text_area('Extracted Text', extracted_text, height=500)\n",
        "\n",
        "        with col3:\n",
        "            st.image(denoised_image_3, caption='Bilateral Filtering', use_column_width=True, clamp=True, channels=\"GRAY\", width=denoised_width)\n",
        "            if st.button('Bilateral Filtering OCR'):\n",
        "                extracted_text = extract_text_from_image(denoised_image_3)\n",
        "                st.text_area('Extracted Text', extracted_text, height=500)\n",
        "# Run the app\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "ME8p2T8sS0XL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install streamlit -q\n",
        "!wget -q -O - ipv4.icanhazip.com\n",
        "! streamlit run aniso.py & npx localtunnel --port 8501\n"
      ],
      "metadata": {
        "id": "IIeWCrZjS0UU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}